# ğŸ½ï¸ EasyDiner Web Scraping & Data Analysis Project

## ğŸ“Œ Project Overview
This project focuses on web scraping restaurant data from the EasyDiner website and performing data cleaning, exploratory data analysis (EDA), and insights generation. The objective is to extract meaningful information such as restaurant details, ratings, cuisines, locations, and offers to identify dining trends and support data-driven decisions.

This is an end-to-end data analysis project suitable for GitHub portfolios and interviews.

## ğŸ¯ Objectives
- Scrape restaurant data from EasyDiner across multiple cities
- Handle dynamic and inconsistent web data
- Clean and preprocess the collected data
- Perform exploratory data analysis (EDA)
- Generate meaningful insights about restaurants, ratings, and trends

## ğŸ› ï¸ Tech Stack
- Programming Language: Python
- Libraries: BeautifulSoup, Requests, Pandas, NumPy, Matplotlib, Seaborn
- Tools: Jupyter Notebook, VS Code

## ğŸ“‚ Project Structure
EasyDiner-Web-Scraping/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data.csv
â”‚   â””â”€â”€ cleaned_data.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper.py
â”‚   â””â”€â”€ data_cleaning.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

## ğŸ” Data Collected
- Restaurant Name
- City
- Cuisine Types
- Ratings
- Price Range
- Offers / Discounts
- Restaurant Location

## âš™ï¸ Key Features
- Automated scraping for multiple cities
- Robust handling of missing and inconsistent data
- Ethical scraping with proper rate limiting
- Clean and structured dataset ready for analysis
- Insightful visualizations and summaries

## ğŸ“Š Analysis & Insights
- Distribution of restaurant ratings across cities
- Popular cuisines by location
- Relationship between ratings and price range
- City-wise restaurant availability trends

## ğŸš€ How to Run the Project
1. Clone the repository  
   git clone https://github.com/your-username/eazydiner-web-scraping.git  
2. Install dependencies  
   pip install -r requirements.txt  
3. Run the scraper  
   python scripts/scraper.py  
4. Open the analysis notebook  
   notebooks/analysis.ipynb  

## âš ï¸ Disclaimer
This project is created for educational purposes only. All data used is publicly available, and scraping was performed responsibly.

## ğŸ“Œ Future Improvements
- Add Selenium for fully dynamic pages
- Build dashboards using Power BI or Streamlit
- Schedule automated scraping
- Perform sentiment analysis on reviews

## ğŸ‘©â€ğŸ’» Author
Gayathri Lanke  
Aspiring Data Scientist | Python | Web Scraping | Data Analysis

â­ If you find this project useful, feel free to star the repository!
